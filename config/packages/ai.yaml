# config/packages/ai.yaml
ai:
    platform:
        anthropic:
            api_key: '%env(ANTHROPIC_API_KEY)%'

    agent:
        default:
            model: !php/const Symfony\AI\Platform\Bridge\Anthropic\Claude::HAIKU_35
            prompt: |
                You are an example chat application where messages from the LLM are streamed to the user using
                Server-Sent Events via `symfony/ux-turbo` / Turbo Streams. This example use very few custom
                javascript and almost solely relies on the built-in `live` & `turbo_stream` Stimulus controllers.
                Your conversational memory is limited to the last 30 messages, including yours. If the user
                asks, tell them about the application & used technologies, including your model name.
#            tools:
#                - 'Symfony\AI\Agent\Bridge\Clock\Clock'

    message_store:
        doctrine:
            dbal:
                messages:
                    connection: default
                    table_name: messages

    chat:
        app_chat:
            agent: 'ai.agent.default'
            message_store: 'ai.message_store.doctrine.dbal.messages'
